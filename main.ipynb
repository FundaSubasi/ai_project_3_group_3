{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55209cbb-9dce-4481-8c88-ac870c76c524",
   "metadata": {},
   "source": [
    "# Disease Recommendation/Prediction Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5a8d1-5510-4b66-a0c1-9dae9b0aa20a",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24792e46-81e3-4388-9ea7-57890195e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import pandas as pd # pandas is used for data manipulation and analysis\n",
    "import numpy as np  # numpy is used for numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f74c62b-66dd-4906-828a-6e937923a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "\n",
    "# Load the dataset containing diseases and symptoms\n",
    "dataset_df = pd.read_csv('resources/dataset.csv') # reading the dataset.csv file into a pandas DataFrame\n",
    "\n",
    "# Load the symptom severity dataset\n",
    "severity_df = pd.read_csv('resources/Symptom-severity.csv') # reading the Symptom-severity.csv file into a pandas DataFrame\n",
    "\n",
    "# Load the synthetic disease data for testing\n",
    "synthetic_test_df = pd.read_csv('resources/synthetic_disease_data.csv') # reading the synthetic_disease_data.csv file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5892a707-d200-4a3e-a9dc-4f4dc92bc766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset (diseases and symptoms):\n",
      "            Disease   Symptom_1              Symptom_2              Symptom_3  \\\n",
      "0  Fungal infection     itching              skin_rash   nodal_skin_eruptions   \n",
      "1  Fungal infection   skin_rash   nodal_skin_eruptions    dischromic _patches   \n",
      "2  Fungal infection     itching   nodal_skin_eruptions    dischromic _patches   \n",
      "3  Fungal infection     itching              skin_rash    dischromic _patches   \n",
      "4  Fungal infection     itching              skin_rash   nodal_skin_eruptions   \n",
      "\n",
      "              Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  \\\n",
      "0   dischromic _patches       NaN       NaN       NaN       NaN       NaN   \n",
      "1                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "2                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "3                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "4                   NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "\n",
      "  Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "  Symptom_16 Symptom_17  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "\n",
      "Symptom Severity Dataset:\n",
      "                Symptom  weight\n",
      "0               itching       1\n",
      "1             skin_rash       3\n",
      "2  nodal_skin_eruptions       4\n",
      "3   continuous_sneezing       4\n",
      "4             shivering       5\n",
      "\n",
      "Synthetic Disease Test Dataset:\n",
      "                                   Disease              Symptom_1  \\\n",
      "0                              Hepatitis C         family_history   \n",
      "1                  Urinary tract infection    burning_micturition   \n",
      "2                                Psoriasis   small_dents_in_nails   \n",
      "3  (vertigo) Paroymsal  Positional Vertigo        loss_of_balance   \n",
      "4                                Arthritis     movement_stiffness   \n",
      "\n",
      "          Symptom_2         Symptom_3 Symptom_4 Symptom_5 Symptom_6 Symptom_7  \\\n",
      "0               NaN               NaN       NaN       NaN       NaN       NaN   \n",
      "1               NaN               NaN       NaN       NaN       NaN       NaN   \n",
      "2         skin_rash        joint_pain       NaN       NaN       NaN       NaN   \n",
      "3               NaN               NaN       NaN       NaN       NaN       NaN   \n",
      "4   painful_walking   swelling_joints       NaN       NaN       NaN       NaN   \n",
      "\n",
      "  Symptom_8 Symptom_9 Symptom_10 Symptom_11 Symptom_12 Symptom_13 Symptom_14  \\\n",
      "0       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "1       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "2       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "3       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4       NaN       NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "  Symptom_15 Symptom_16 Symptom_17  \n",
      "0        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the datasets to understand their structure and contents\n",
    "\n",
    "# Display the first few rows of the dataset containing diseases and symptoms\n",
    "print(\"Dataset (diseases and symptoms):\")\n",
    "print(dataset_df.head()) # displaying the first 5 rows of dataset_df\n",
    "\n",
    "# Display the first few rows of the symptom severity dataset\n",
    "print(\"\\nSymptom Severity Dataset:\")\n",
    "print(severity_df.head()) # displaying the first 5 rows of severity_df\n",
    "\n",
    "# Display the first few rows of the synthetic disease test dataset\n",
    "print(\"\\nSynthetic Disease Test Dataset:\")\n",
    "print(synthetic_test_df.head()) # displaying the first 5 rows of synthetic_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d9d55-491f-41e8-9637-39cdfb948f33",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe507519-914f-43df-b659-eaf91109d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the symptom severity data with the main dataset\n",
    "# Ensure the severity_df has unique symptoms and no duplicates\n",
    "\n",
    "# Drop any duplicate symptom names in severity_df, keeping the first occurrence\n",
    "severity_df = severity_df.drop_duplicates(subset='Symptom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2145bc1c-4aed-4f53-8c8b-b2feb36d9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new column for each symptom's weight\n",
    "for col in dataset_df.columns[1:]:\n",
    "    dataset_df[col + '_weight'] = dataset_df[col].map(severity_df.set_index('Symptom')['weight']) # mapping symptoms to their weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97cdc5a2-283f-4527-bc4a-a29422bfc0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after adding symptom weights:\n",
      "            Disease  Symptom_1             Symptom_2             Symptom_3  \\\n",
      "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
      "1  Fungal infection  skin_rash  nodal_skin_eruptions   dischromic _patches   \n",
      "2  Fungal infection    itching  nodal_skin_eruptions   dischromic _patches   \n",
      "3  Fungal infection    itching             skin_rash   dischromic _patches   \n",
      "4  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
      "\n",
      "             Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  ...  \\\n",
      "0  dischromic _patches       NaN       NaN       NaN       NaN       NaN  ...   \n",
      "1                  NaN       NaN       NaN       NaN       NaN       NaN  ...   \n",
      "2                  NaN       NaN       NaN       NaN       NaN       NaN  ...   \n",
      "3                  NaN       NaN       NaN       NaN       NaN       NaN  ...   \n",
      "4                  NaN       NaN       NaN       NaN       NaN       NaN  ...   \n",
      "\n",
      "  Symptom_8_weight Symptom_9_weight Symptom_10_weight Symptom_11_weight  \\\n",
      "0              NaN              NaN               NaN               NaN   \n",
      "1              NaN              NaN               NaN               NaN   \n",
      "2              NaN              NaN               NaN               NaN   \n",
      "3              NaN              NaN               NaN               NaN   \n",
      "4              NaN              NaN               NaN               NaN   \n",
      "\n",
      "  Symptom_12_weight Symptom_13_weight Symptom_14_weight Symptom_15_weight  \\\n",
      "0               NaN               NaN               NaN               NaN   \n",
      "1               NaN               NaN               NaN               NaN   \n",
      "2               NaN               NaN               NaN               NaN   \n",
      "3               NaN               NaN               NaN               NaN   \n",
      "4               NaN               NaN               NaN               NaN   \n",
      "\n",
      "   Symptom_16_weight  Symptom_17_weight  \n",
      "0                NaN                NaN  \n",
      "1                NaN                NaN  \n",
      "2                NaN                NaN  \n",
      "3                NaN                NaN  \n",
      "4                NaN                NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# The resulting dataset_df will now include the weights associated with each symptom.\n",
    "print(\"Dataset after adding symptom weights:\")\n",
    "print(dataset_df.head()) # displaying the first 5 rows of the modified dataset_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1957ed37-acce-41aa-a505-9d1d00cf003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in the symptom weight columns with 0\n",
    "# This is because not all diseases have 17 symptoms, and the absence of a symptom means its weight should be 0.\n",
    "\n",
    "# Replace NaN values with 0 in all weight columns\n",
    "dataset_df.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd6fe675-4931-43f3-9291-0557f0d350c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after replacing NaN values with 0:\n",
      "            Disease  Symptom_1             Symptom_2             Symptom_3  \\\n",
      "0  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
      "1  Fungal infection  skin_rash  nodal_skin_eruptions    dischromic_patches   \n",
      "2  Fungal infection    itching  nodal_skin_eruptions    dischromic_patches   \n",
      "3  Fungal infection    itching             skin_rash    dischromic_patches   \n",
      "4  Fungal infection    itching             skin_rash  nodal_skin_eruptions   \n",
      "\n",
      "            Symptom_4 Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9  ...  \\\n",
      "0  dischromic_patches         0         0         0         0         0  ...   \n",
      "1                   0         0         0         0         0         0  ...   \n",
      "2                   0         0         0         0         0         0  ...   \n",
      "3                   0         0         0         0         0         0  ...   \n",
      "4                   0         0         0         0         0         0  ...   \n",
      "\n",
      "  Symptom_8_weight Symptom_9_weight Symptom_10_weight Symptom_11_weight  \\\n",
      "0              0.0              0.0               0.0               0.0   \n",
      "1              0.0              0.0               0.0               0.0   \n",
      "2              0.0              0.0               0.0               0.0   \n",
      "3              0.0              0.0               0.0               0.0   \n",
      "4              0.0              0.0               0.0               0.0   \n",
      "\n",
      "  Symptom_12_weight Symptom_13_weight Symptom_14_weight Symptom_15_weight  \\\n",
      "0               0.0               0.0               0.0               0.0   \n",
      "1               0.0               0.0               0.0               0.0   \n",
      "2               0.0               0.0               0.0               0.0   \n",
      "3               0.0               0.0               0.0               0.0   \n",
      "4               0.0               0.0               0.0               0.0   \n",
      "\n",
      "   Symptom_16_weight  Symptom_17_weight  \n",
      "0                0.0                0.0  \n",
      "1                0.0                0.0  \n",
      "2                0.0                0.0  \n",
      "3                0.0                0.0  \n",
      "4                0.0                0.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the updated dataset to confirm the changes\n",
    "print(\"Dataset after replacing NaN values with 0:\")\n",
    "print(dataset_df.head()) # displaying the first 5 rows of the modified dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95fdd1cd-5d0e-4283-b8ac-bda60d535e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total weight for each disease based on the symptoms\n",
    "# We will now calculate a 'weight_total' column that sums up the weights of all symptoms for each disease.\n",
    "\n",
    "# Calculate the total weight for each row (disease)\n",
    "weight_columns = [col for col in dataset_df.columns if '_weight' in col] # selecting all weight columns\n",
    "dataset_df['weight_total'] = dataset_df[weight_columns].sum(axis=1) # summing the weights across the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2fe63f2-8893-4353-9924-d5ff2b31329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after calculating total weight for each disease:\n",
      "            Disease  weight_total\n",
      "0  Fungal infection          14.0\n",
      "1  Fungal infection          13.0\n",
      "2  Fungal infection          11.0\n",
      "3  Fungal infection          10.0\n",
      "4  Fungal infection           8.0\n"
     ]
    }
   ],
   "source": [
    "# Display the updated dataset with the 'weight_total' column\n",
    "print(\"Dataset after calculating total weight for each disease:\")\n",
    "print(dataset_df[['Disease', 'weight_total']].head()) # displaying the first 5 rows with Disease and weight_total columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95db3a99-498e-4888-8e4c-36548b01754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved successfully to resources/combined_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path to save the file\n",
    "output_file_path = 'resources/combined_dataset.csv'\n",
    "\n",
    "# Save the updated dataset as a CSV file\n",
    "dataset_df.to_csv(output_file_path, index=False) # saving the DataFrame to a CSV file without the index\n",
    "\n",
    "print(f\"Updated dataset saved successfully to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3dcb0-4048-4677-baea-1bf4a3c7ffb9",
   "metadata": {},
   "source": [
    "## Prepare the data for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef874a4f-ad8b-48ba-b0ac-fe513402500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined dataset from the 'resources' folder\n",
    "combined_dataset_df = pd.read_csv('resources/combined_dataset.csv') # reading the combined_dataset.csv file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761db1ef-6d7b-4e6a-a47e-35ef5e92c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature columns (all symptom and weight columns)\n",
    "feature_columns = [col for col in combined_dataset_df.columns if col.startswith('Symptom')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8ae552b4-097f-45f6-94e2-d3b4acaf7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target column (disease)\n",
    "target_column = 'Disease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ea31296-fe12-48af-a2f8-54be0af85052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the target\n",
    "X = combined_dataset_df[feature_columns]  # features (symptoms and their weights)\n",
    "y = combined_dataset_df[target_column]    # target (disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9558dc2d-5e02-472c-aebb-5c6b80197bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X) shape: (4920, 34)\n",
      "Target (y) shape: (4920,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of X and y to ensure everything is correct\n",
    "print(\"Features (X) shape:\", X.shape)\n",
    "print(\"Target (y) shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84a858dc-5e34-447e-b05e-33403879186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# We will now split the dataset into training and testing sets to evaluate the performance of the deep learning models.\n",
    "\n",
    "from sklearn.model_selection import train_test_split # importing train_test_split for data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "319ec8dc-32f1-4478-8e12-ffe5638fae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data: 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b17d855-8ffa-47c5-baec-95e217425e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features (X_train) shape: (3936, 34)\n",
      "Testing features (X_test) shape: (984, 34)\n",
      "Training target (y_train) shape: (3936,)\n",
      "Testing target (y_test) shape: (984,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the training and testing sets to confirm the split\n",
    "print(\"Training features (X_train) shape:\", X_train.shape)\n",
    "print(\"Testing features (X_test) shape:\", X_test.shape)\n",
    "print(\"Training target (y_train) shape:\", y_train.shape)\n",
    "print(\"Testing target (y_test) shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e084d5f9-fe57-424f-abb0-a99fbc6cf212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize only the numeric feature data (symptom weights)\n",
    "# We will normalize the symptom weight columns to ensure that the model training process is efficient and that the models converge properly.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # importing StandardScaler for feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "95f7acc0-812b-4d87-b395-2119a94b3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the weight columns that need to be scaled\n",
    "weight_columns = [col for col in X.columns if '_weight' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "983ef491-e86c-428f-b4de-707112455bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b51dafb-61de-42c1-b1e6-4260cead2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on the training data and transform both training and testing data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[weight_columns] = scaler.fit_transform(X_train[weight_columns]) # fitting and transforming the training data\n",
    "X_test_scaled[weight_columns] = scaler.transform(X_test[weight_columns])       # transforming the testing data using the same scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "06e85fcf-e2c8-4cb4-889a-17a1b8053e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the scaled training features (X_train_scaled):\n",
      "      Symptom_1_weight  Symptom_2_weight  Symptom_3_weight  Symptom_4_weight  \\\n",
      "1807         -1.812392         -0.932567         -0.057841         -1.067440   \n",
      "184          -0.298315          0.696270         -0.057841          1.634801   \n",
      "205          -1.812392         -0.118149         -1.536180          0.013456   \n",
      "4581          0.458724         -0.118149         -0.057841          0.013456   \n",
      "410          -1.812392         -0.932567         -0.057841          1.094353   \n",
      "\n",
      "      Symptom_5_weight  Symptom_6_weight  Symptom_7_weight  Symptom_8_weight  \\\n",
      "1807          1.769614          0.134829          1.260963          1.911182   \n",
      "184          -0.086041          0.972538          0.832366          1.020692   \n",
      "205           0.377873          0.553684          0.832366          1.020692   \n",
      "4581          0.841787          0.972538          1.689560         -0.760287   \n",
      "410          -1.477782         -1.121734         -0.882021         -0.760287   \n",
      "\n",
      "      Symptom_9_weight  Symptom_10_weight  Symptom_11_weight  \\\n",
      "1807          1.984440           0.834003          -0.518063   \n",
      "184           1.539408           1.321619          -0.518063   \n",
      "205           1.984440           1.809236           0.555146   \n",
      "4581         -0.685752          -0.628847          -0.518063   \n",
      "410          -0.685752          -0.628847          -0.518063   \n",
      "\n",
      "      Symptom_12_weight  Symptom_13_weight  Symptom_14_weight  \\\n",
      "1807          -0.387763          -0.320725          -0.248228   \n",
      "184           -0.387763          -0.320725          -0.248228   \n",
      "205           -0.387763          -0.320725          -0.248228   \n",
      "4581          -0.387763          -0.320725          -0.248228   \n",
      "410           -0.387763          -0.320725          -0.248228   \n",
      "\n",
      "      Symptom_15_weight  Symptom_16_weight  Symptom_17_weight  \n",
      "1807           -0.21803          -0.192106          -0.123361  \n",
      "184            -0.21803          -0.192106          -0.123361  \n",
      "205            -0.21803          -0.192106          -0.123361  \n",
      "4581           -0.21803          -0.192106          -0.123361  \n",
      "410            -0.21803          -0.192106          -0.123361  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the scaled training data to confirm\n",
    "print(\"First few rows of the scaled training features (X_train_scaled):\")\n",
    "print(X_train_scaled[weight_columns].head()) # displaying the scaled weight columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835df128-cde3-41f2-be2e-81a658f992f4",
   "metadata": {},
   "source": [
    "## Select and Train Deep Learning Models\n",
    "Here we will train, test and compare three deep learning models to see which one performs the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a774586-2af5-4a96-87d8-1f8a6eba644e",
   "metadata": {},
   "source": [
    "\r\n",
    "##### Three top-performing deep learning models commonly used for multi-class classification tasks:\r\n",
    "\r\n",
    "**Model 1: Multi-Layer Perceptron (MLP)**  \r\n",
    "   - A fully connected feedforward neural network.\r\n",
    "   - Suitable for tabular data with independent features.\r\n",
    "   - Uses multiple layers to learn complex patterns.\r\n",
    "   - **Pro:** Simple and effective for structured data.\r\n",
    "   - **Con:** Struggles with spatial or sequential data.\r\n",
    "\r\n",
    "**Model 2: Convolutional Neural Network (CNN)**  \r\n",
    "   - Designed to capture local patterns in data.\r\n",
    "   - Typically used for image data but adaptable to other data types.\r\n",
    "   - Includes convolutional layers and pooling layers for feature extraction.\r\n",
    "   - **Pro:** Excellent for data with spatial relationships.\r\n",
    "   - **Con:** Computationally intensive, especially with large datasets.\r\n",
    "\r\n",
    "**Model 3: Recurrent Neural Network (RNN) with LSTM units**  \r\n",
    "   - Captures dependencies in sequence data.\r\n",
    "   - LSTM units address the vanishing gradient problem.\r\n",
    "   - Maintains a memory of previous inputs for better sequence prediction.\r\n",
    "   - **Pro:** Powerful for tasks involving temporal dependencies.\r\n",
    "   - **Con:** Less effective for non-sequential data and can be slower to train.\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c0320-5a06-4a10-8834-ff04dc2798d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf0cb0-3493-4a06-b577-71f5c15c14a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994816f3-510d-4a83-aa74-a564c5894d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d89b9ae-4c53-49b6-bfdd-1ed45fb71a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6099c6e-cd72-4a23-b8d5-b60fe972b362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24893f88-cf92-417f-9cf1-addfb941391d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb5a52-71b8-460d-9f03-407b1e430fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff8d07-dfea-45d4-b2c0-bd6e8e7e2139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74294ed8-6079-4329-8c69-c8e1872a25a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335d10d-807a-4520-9625-29272072bd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
